<!DOCTYPE html>
<html lang="zh-Hant">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>手機手寫辨識數字程式</title>
  <!-- 載入 TensorFlow.js -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
  <style>
    body {
      font-family: sans-serif;
      text-align: center;
      margin: 20px;
    }
    canvas {
      background: #fff;
      touch-action: none; /* 避免瀏覽器預設的觸控縮放 */
    }
    button {
      margin: 10px;
      padding: 10px 20px;
      font-size: 16px;
    }
  </style>
</head>
<body>
  <h1>手寫數字辨識</h1>
  <!-- Canvas 區域，這裡設定 280x280 像素，方便以較大比例繪製，再縮放回 28x28 -->
  <canvas id="canvas" width="280" height="280" style="border: 1px solid #000;"></canvas>
  <br>
  <button id="clear">清除</button>
  <button id="predict">辨識</button>
  <p>辨識結果：<span id="result"></span></p>

  <script>
    // 取得 canvas 元素與 2D 繪圖上下文
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    let drawing = false;

    // 設定畫筆屬性
    ctx.lineWidth = 20;
    ctx.lineCap = 'round';
    ctx.strokeStyle = '#000';

    // 處理滑鼠事件
    canvas.addEventListener('mousedown', function(e) {
      drawing = true;
      ctx.beginPath();
      ctx.moveTo(e.offsetX, e.offsetY);
    });
    canvas.addEventListener('mousemove', function(e) {
      if (drawing) {
        ctx.lineTo(e.offsetX, e.offsetY);
        ctx.stroke();
      }
    });
    canvas.addEventListener('mouseup', function() {
      drawing = false;
    });
    
    // 處理觸控事件（手機裝置）
    canvas.addEventListener('touchstart', function(e) {
      e.preventDefault();
      const touch = e.touches[0];
      const rect = canvas.getBoundingClientRect();
      const x = touch.clientX - rect.left;
      const y = touch.clientY - rect.top;
      drawing = true;
      ctx.beginPath();
      ctx.moveTo(x, y);
    });
    canvas.addEventListener('touchmove', function(e) {
      e.preventDefault();
      if (drawing) {
        const touch = e.touches[0];
        const rect = canvas.getBoundingClientRect();
        const x = touch.clientX - rect.left;
        const y = touch.clientY - rect.top;
        ctx.lineTo(x, y);
        ctx.stroke();
      }
    });
    canvas.addEventListener('touchend', function(e) {
      drawing = false;
    });

    // 清除按鈕：重設 canvas 與結果顯示區
    document.getElementById('clear').addEventListener('click', function() {
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      document.getElementById('result').textContent = '';
    });

    // 載入預訓練的 MNIST 模型
    let model;
    (async function(){
      model = await tf.loadLayersModel('https://storage.googleapis.com/tfjs-models/tfjs/mnist_tfjs_model/model.json');
      console.log('模型載入完成');
    })();

    // 辨識按鈕：擷取畫布圖像、預處理，並進行模型預測
    document.getElementById('predict').addEventListener('click', async function() {
      // 從 Canvas 擷取圖像，僅取得單一色道（灰階）
      let img = tf.browser.fromPixels(canvas, 1);
      // 將圖像縮放至 28x28（MNIST 標準尺寸）
      let resized = tf.image.resizeBilinear(img, [28, 28]);
      // 重塑 tensor 形狀為 [1, 28, 28, 1] ，符合模型輸入形狀
      let tensor = resized.reshape([1, 28, 28, 1]);
      // 將像素值標準化到 [0, 1] 區間
      tensor = tensor.div(255.0);

      // 使用模型進行預測
      let prediction = model.predict(tensor);
      // 取出預測結果中機率最高的數字
      let predictedValue = prediction.argMax(1).dataSync()[0];

      // 在頁面上顯示辨識結果
      document.getElementById('result').textContent = predictedValue;

      // 清理 TensorFlow.js 佔用的資源
      tf.dispose([img, resized, tensor, prediction]);
    });
  </script>
</body>
</html>